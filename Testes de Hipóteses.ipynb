{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import math\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testeSobreposicao(intervalo1, intervalo2):\n",
    "    p = (intervalo1[0] >= intervalo2[0] and intervalo1[0] <= intervalo2[1])\n",
    "    q = (intervalo2[0] >= intervalo1[0] and intervalo2[0] <= intervalo1[1])\n",
    "\n",
    "    return q or p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testeDiferencasMedias(acuracias1, acuracias2):\n",
    "\n",
    "    diferencas = []\n",
    "\n",
    "    for i,j in zip(acuracias1, acuracias2):\n",
    "        diferencas.append(i - j)\n",
    "\n",
    "    #media = sum(diferencas)/float(len(diferencas))\n",
    "    \n",
    "    intervalo = st.t.interval(0.95, len(diferencas)-1, loc=np.mean(diferencas), scale=st.sem(diferencas))\n",
    "\n",
    "    return ((intervalo[0] <= 0 and intervalo[1] >= 0), intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testeWilcoxon(acc1, acc2):\n",
    "    linha = []\n",
    "    tabela = []\n",
    "    \n",
    "    for i,j in zip(acc1, acc2):\n",
    "        linha.append(i)\n",
    "        linha.append(j)\n",
    "        linha.append(j - i)\n",
    "        linha.append(abs(j - i))\n",
    "        tabela.append(linha)\n",
    "        linha = []\n",
    "\n",
    "    tabela.sort(key = itemgetter(3))\n",
    "\n",
    "    ranks = range(1,len(tabela)+1)\n",
    "\n",
    "    i = 0\n",
    "    while(i < len(acc1)):\n",
    "        j = 1\n",
    "        media = ranks[i]\n",
    "        while(i != len(acc1) - 1 and tabela[i][3] == tabela[i+j][3]):\n",
    "            media += ranks[i+j]\n",
    "            j += 1\n",
    "        for k in range(j):\n",
    "            tabela[i+k].append(media/float(j))\n",
    "        i += j\n",
    "\n",
    "\n",
    "    rankNulo = 0\n",
    "    rankPositivo = 0\n",
    "    rankNegativo = 0\n",
    "    \n",
    "    for t in tabela:\n",
    "        if(t[2] == 0):\n",
    "            rankNulo += t[4]\n",
    "        elif(t[2] > 0):\n",
    "            rankPositivo += t[4]\n",
    "        else:\n",
    "            rankNegativo += t[4]\n",
    "    \n",
    "    Rmais = rankPositivo + (0.5 * rankNulo)\n",
    "    Rmenos = rankNegativo + (0.5 * rankNulo)\n",
    "\n",
    "    S = min(Rmais, Rmenos)\n",
    "    N = len(tabela)\n",
    "    \n",
    "    Z = S - (0.25 * N * (N - 1))\n",
    "    Z = Z / math.sqrt(1/24. * N * (N + 1) * (2 * N + 1))\n",
    "    \n",
    "    return abs(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET: yale\n",
      "\n",
      "TESTES DE HIPOSTESE (95% de confianca):\n",
      "[+] Teste de Sobreposicao: \n",
      "H0 nao rejeitada. Concluimos que os classificadores tem desempenhos iguais\n",
      "[+] Teste de Diferenca das Medias: \n",
      "H0 rejeitada. Concluimos que os calssificadores nao sao iguais em desempenho\n",
      "Eigenfaces Proposto eh melhor para essa base\n",
      "[+] Teste de Wilcoxon: \n",
      "H0 rejeitada. Concluimos que os calssificadores nao sao iguais em desempenho\n",
      "Eigenfaces Proposto eh melhor para essa base\n"
     ]
    }
   ],
   "source": [
    "n_experimento = 3\n",
    "experimento_folder = 'Experimento'+str(n_experimento)\n",
    "\n",
    "d = 'yale'\n",
    "print('\\nDATASET: '+d)\n",
    "file1 = experimento_folder+'\\\\'+'acc\\\\'+'acc_'+d+'_eigenfaces.csv'\n",
    "file2 = experimento_folder+'\\\\'+'acc\\\\'+'acc_'+d+'_eigenfaces_proposed.csv'\n",
    "\n",
    "classificador1 = (\"Eigenfaces\",file1)\n",
    "classificador2 = (\"Eigenfaces Proposto\",file2)\n",
    "\n",
    "acc_classificador1 = np.genfromtxt(classificador1[1], delimiter=',')\n",
    "acc_classificador2 = np.genfromtxt(classificador2[1], delimiter=',')\n",
    "\n",
    "taxa = 1.96\n",
    "\n",
    "#intervalos de confianca\n",
    "int1 = st.t.interval(0.95, len(acc_classificador1)-1, loc=np.mean(acc_classificador1), scale=st.sem(acc_classificador1))\n",
    "int2 = st.t.interval(0.95, len(acc_classificador2)-1, loc=np.mean(acc_classificador2), scale=st.sem(acc_classificador2))\n",
    "\n",
    "\n",
    "print('\\nTESTES DE HIPOSTESE (95% de confianca):')\n",
    "print('[+] Teste de Sobreposicao: ')\n",
    "if(testeSobreposicao(int1, int2)):\n",
    "    print('H0 nao rejeitada. Concluimos que os classificadores tem desempenhos iguais')\n",
    "else:\n",
    "    print('H0 rejeitada. Concluimos que os calssificadores nao sao iguais em desempenho')\n",
    "    if(acc_classificador1.mean() > acc_classificador2.mean()):\n",
    "        print('{0} eh melhor para essa base'.format(classificador1[0]))\n",
    "    else:\n",
    "        print('{0} eh melhor para essa base'.format(classificador2[0]))\n",
    "\n",
    "print('[+] Teste de Diferenca das Medias: ')\n",
    "if(testeDiferencasMedias(int1, int2)[0]):\n",
    "    print('H0 nao rejeitada. Concluimos que os classificadores tem desempenhos iguais')\n",
    "else:\n",
    "    print('H0 rejeitada. Concluimos que os calssificadores nao sao iguais em desempenho')\n",
    "    if(acc_classificador1.mean() > acc_classificador2.mean()):\n",
    "        print('{0} eh melhor para essa base'.format(classificador1[0]))\n",
    "    else:\n",
    "        print('{0} eh melhor para essa base'.format(classificador2[0]))\n",
    "\n",
    "print('[+] Teste de Wilcoxon: ')\n",
    "\n",
    "if(testeWilcoxon(acc_classificador1, acc_classificador2) > taxa):\n",
    "    print('H0 rejeitada. Concluimos que os calssificadores nao sao iguais em desempenho')\n",
    "    if(acc_classificador1.mean() > acc_classificador2.mean()):\n",
    "        print('{0} eh melhor para essa base'.format(classificador1[0]))\n",
    "    else:\n",
    "        print('{0} eh melhor para essa base'.format(classificador2[0]))\n",
    "else:\n",
    "    print('H0 nao rejeitada. Concluimos que os classificadores tem desempenhos iguais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
